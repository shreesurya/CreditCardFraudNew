{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Helper for detecting Interactive vs Commit session-mode\n",
    "def is_interactive():\n",
    "    return 'runtime' in get_ipython().config.IPKernelApp.connection_file\n",
    "\n",
    "# Config\n",
    "isPretty = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Importing training data...')\n",
    "\n",
    "\n",
    "#Enter the file path of your .csv file..\n",
    "X = pd.read_csv('/home/user/CyberSecurity/ieee-fraud-detection/train_transaction.csv')\n",
    "X_id = pd.read_csv('/home/user/CyberSecurity/ieee-fraud-detection/train_identity.csv')\n",
    "X = pd.merge(X, X_id, on='TransactionID', how='left')\n",
    "del X_id\n",
    "\n",
    "target = 'isFraud'\n",
    "indexCol = 'TransactionID'\n",
    "remove_features = [target]\n",
    "features = [col for col in list(X) if col not in remove_features]\n",
    "labelEncoders = {}\n",
    "\n",
    "y = X[target]\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isPretty:\n",
    "    fradulentTx = X[X['isFraud'] == 1]\n",
    "    validTx = X[X['isFraud'] == 0]\n",
    "\n",
    "    # How many transactions are fraudulent?\n",
    "    fig, ax = plt.subplots()\n",
    "    ax = X['isFraud'].value_counts(normalize=True).map(lambda x: x * 100).plot.bar() # % isFraud in training data\n",
    "    ax.title.set_text('How many transactions are fraudulent?')\n",
    "\n",
    "    # Which card types are most associated with fraud?\n",
    "    cardTypeFraud = fradulentTx['card4'].value_counts(normalize=True).map(lambda x: x * 100).to_frame().reset_index()\n",
    "    cardTypeFraud.columns = ['card_type', 'fraud_freq']\n",
    "    cardTypeValid = validTx['card4'].value_counts(normalize=True).map(lambda x: x * 100).to_frame().reset_index()\n",
    "    cardTypeValid.columns = ['card_type', 'valid_freq']\n",
    "    cardType = pd.merge(cardTypeFraud, cardTypeValid, on='card_type')\n",
    "    cardType['dif'] = cardType['fraud_freq'] - cardType['valid_freq']\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.barplot(x=\"card_type\", y=\"dif\", data=cardType, ax=ax)\n",
    "    ax.title.set_text('Which card types are most associated with fraud?')\n",
    "\n",
    "    # Which tx amounts under $500 are most associated with fraud?\n",
    "    txUnder500 = X[X['TransactionAmt'] < 500][['TransactionAmt', 'card4']]\n",
    "    txUnder500.columns = ['amount', 'card_type']\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.violinplot(x=\"card_type\", y=\"amount\", split=True, inner=\"quart\", data=txUnder500, ax=ax)\n",
    "    ax.title.set_text('Which tx amounts are most associated with fraud?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertLabels(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtypes == np.object:\n",
    "            uniques = df[col].unique()\n",
    "            labelEncoders[col] = preprocessing.LabelEncoder()\n",
    "            labelEncoders[col].fit(uniques)\n",
    "            labelEncoderDict = dict(zip(labelEncoders[col].classes_, labelEncoders[col].transform(labelEncoders[col].classes_)))\n",
    "            df[col] = df[col].apply(lambda x: labelEncoderDict.get(x, '<UNK>'))\n",
    "\n",
    "def convertToType(dfCol, npType): # Convert to numpy type\n",
    "    dfCol = dfCol.astype(npType)\n",
    "\n",
    "def convertToFloat32(df): # Convert numeric data to float32 or int32\n",
    "    for col in df.columns:\n",
    "        if df[col].dtypes != np.object and df[col].dtypes != np.int32:\n",
    "            convertToType(df[col], np.float32)\n",
    "            \n",
    "def fillCatNan(df, filler): # Fill missing string values\n",
    "    for col in df.columns:\n",
    "        if df[col].dtypes == np.object:\n",
    "            df[col].fillna(filler, inplace=True)\n",
    "            \n",
    "def fillValNan(df, filler): # Fill missing numeric values\n",
    "    for col in df.columns:\n",
    "        if df[col].dtypes != np.object:\n",
    "            df[col].fillna(0.0, inplace=True)\n",
    "            \n",
    "def scaleVals(df, target): # Scale values\n",
    "    for col in df.columns:\n",
    "        if col != target and col != indexCol and df[col].dtypes != np.object:\n",
    "            scaler = RobustScaler().fit(df[col].values.reshape(-1, 1))\n",
    "            df[col] = scaler.transform(df[col].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    convertToType(df[indexCol], np.int32)\n",
    "    fillCatNan(df ,'<UNK>')\n",
    "    fillValNan(df , 0.0)\n",
    "    convertLabels(df)\n",
    "    scaleVals(df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Converting to float32...')\n",
    "\n",
    "X = X[features] # Only keep feature columns\n",
    "preprocess(X) # Fill missing values / Reduce memory footprint\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training...')\n",
    "\n",
    "model = LogisticRegression()\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=0)\n",
    "\n",
    "# Loop through the splits (only one)\n",
    "for train_indices, test_indices in splitter.split(X, y):\n",
    "    # Select the train and validation data\n",
    "    X_train, y_train = X.iloc[train_indices], y.iloc[train_indices]\n",
    "    X_test, y_test = X.iloc[test_indices], y.iloc[test_indices]\n",
    "\n",
    "    model.fit(X_train, y_train) # Train\n",
    "    y_pred = model.predict(X_test) # Predict\n",
    "    print(classification_report(y_test, y_pred)) # Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Importing testing data...')\n",
    "#Enter the file path of your .csv file..\n",
    "P = pd.read_csv('/home/user/CyberSecurity/ieee-fraud-detection/test_transaction.csv')\n",
    "#Enter the file path of your .csv file..\n",
    "P_id = pd.read_csv('/home/user/CyberSecurity/ieee-fraud-detection/test_identity.csv')\n",
    "P = pd.merge(P, P_id, on='TransactionID', how='left')[features]\n",
    "del P_id\n",
    "\n",
    "preprocess(P)\n",
    "#print(P)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Calculating predictions...')\n",
    "\n",
    "y_pred = []\n",
    "i, chunksize = 0, 10000\n",
    "for idx in range(0, len(P), chunksize):\n",
    "    batch = P[idx:(i+1)*chunksize]\n",
    "    pred = model.predict_proba(batch) # Predict with probability score\n",
    "    y_pred += list(pred)\n",
    "    i += 1\n",
    "\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred = np.delete(y_pred, 0, axis=1).flatten() # Only keep probability of isFraud==1\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Saving final output...')\n",
    "\n",
    "submission = pd.DataFrame({'TransactionID': P['TransactionID'], 'isFraud': y_pred})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(submission.head())\n",
    "\n",
    "del P, y_pred, submission, model\n",
    "\n",
    "print('Done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
